---
title: Spatial correlation functions
description: "Go over the paper: Extended correlation functions for spatial analedysis of multiplex imaging data, Bull et al. 2024"
authors:
  - name: Nicholas Harbour
format: 
  html:
    embed-resources: true
    code-fold: true
    number-sections: true
    toc: true
    toc-depth: 3
    date-modified: last-modified
    date-format: "MMMM DD, YYYY, HH:mm:ss"
jupyter: python3
---


The link to the GitHub repo for the paper is here <https://github.com/JABull1066/ExtendedCorrelationFunctions>

```{python}

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from helper_functions import *

```




# Synthetic dataset 1


In synthetic dataset I, we randomly position 20 cluster centers in x ≤ 500, and sample 10 points of each cell type from a 2D Gaussian distribution, with standard deviation σ = 20 and mean μ located at the cluster center. In x > 500, the same process is used, but 10 cluster centers are chosen independently for each cell type, leading to a composite point pattern containing 300 cells of each type. By construction, synthetic dataset I exhibits strong colocalization between cells of types C1 and C2 in x ≤ 500, while each cell type is located in independent clusters in x > 500. We assign a second, continuous mark m to cells of type C2. Those with x ≤ 500 are randomly assigned a continuous mark m ∈ 0,0:5 ½w hile those with x >500areassignedamarkm ∈ 0:5,1 ð.C onsequently, when a cluster contains both cell types, cells of type C2 have low marks (m ≤ 0:5), and when it contains only cells of type C2 high marks (m ≥ 0:5) are present.

```{python}

# Generate synthetic data - strong clustering on LHS, weak exclusion on RHS
np.random.seed(1107)
seeds1 = 0.1 + 0.8*np.random.rand(20,2)*np.array([0.5,1]) # 20 random cluster centers in range [0,0.5] and [0.1,0.9]
labs = []
contuslabs = []
points = np.empty(shape=(0,2))
sigma = 0.02
# Cluster process on LHS
for i in range(len(seeds1)):
    # at each cluster center generate 20 points from guassian 
    # I modified this to us np.random.normal instead of np.random.randn
    p = seeds1[i,:] + np.random.normal(0,sigma,size = (20,2))
    # Generate labels that are randomly assigned in LHS so well mixed
    labs.extend(['$C_1$' for v in range(10)])
    contuslabs.extend([np.nan for v in range(10)])
    # contuslabs.extend([0.25 + np.random.rand()*0.25 for v in range(10)])
    labs.extend(['$C_2$' for v in range(10)])
    contuslabs.extend([np.random.rand()*0.5 for v in range(10)]) # value [0,0.5]
    points = np.vstack((points,p))

# Different cluster processes on RHS
# genrate cluster centers distiubted [0.5,0.9] and [0.1,0.9]
seeds2 = 0.1 + 0.8*np.random.rand(20,2)*np.array([0.5,1]) + [0.4,0]
for i in range(len(seeds2)):
    # Each cluster center generates only points from one cell type
    p = seeds2[i,:] + np.random.randn(10,2)*sigma
    if i < len(seeds2)*0.5:
        labs.extend(['$C_1$' for v in range(10)])
        contuslabs.extend([np.nan for v in range(10)])
        # contuslabs.extend([np.random.rand()*0.25 for v in range(10)])
    else:
        labs.extend(['$C_2$' for v in range(10)])
        contuslabs.extend([0.5 + np.random.rand()*0.5 for v in range(10)]) # [0.5,1]
    points = np.vstack((points,p))


points = points*1000

pc = generatePointCloud('Synthetic Dataset I',points,domain=[[0,1000],[0,1000]])
pc.addLabels('Celltype','categorical',labs,cmap='tab10')
pc.addLabels('$m$','continuous',contuslabs,cmap='RdBu_r')

visualisePointCloud(pc,'Celltype',markerSize=100)#,showBoundary=True)
visualisePointCloud(pc,'$m$',markerSize=100,cmap='Oranges')#,showBoundary=True)
c1mask = np.asarray(labs) == '$C_1$'
plt.scatter(points[c1mask,0],points[c1mask,1],s=100,zorder=-1)

```


## Calculate the pair cross-correlation function (PCF) - Synthetic Dataset I

```{python}

#%% Calculate cross-PCFs - Synthetic Dataset I (Fig 2)
a = '$C_1$'
b = '$C_2$'
maxR=500
annulusStep = 1
annulusWidth = 10
r, pcf, contributions = pairCorrelationFunction(pc, 'Celltype', [a,b], maxR=maxR,annulusStep=annulusStep,annulusWidth=annulusWidth)
r2, pcf2, contributions2 = pairCorrelationFunction(pc, 'Celltype', [b,a], maxR=maxR,annulusStep=annulusStep,annulusWidth=annulusWidth)


plt.plot(r,pcf,label='$g_{C_1 C_2}(r)$',linestyle='-')
plt.plot(r2,pcf2,label='$g_{C_2 C_1}(r)$',linestyle=(0,(1,1.5)))
plt.gca().axhline(1,c='k',linestyle=':')
plt.xlabel(r'Radius, $r$ ($\mu$m)')
plt.ylim([0,7])
plt.legend()
plt.show()

```

## TCM

```{python}

#%% Calculate TCMs - Synthetic Dataset I (Fig 2)
tcm = topographicalCorrelationMap(pc,'Celltype','$C_1$','Celltype','$C_2$',radiusOfInterest=10,maxCorrelationThreshold=5.0,kernelRadius=150,kernelSigma=50,visualiseStages=False)

l = int(np.ceil(np.max(np.abs([tcm.min(),tcm.max()]))))
plt.imshow(tcm,cmap='RdBu_r',vmin=-l,vmax=l,origin='lower')
plt.colorbar(label='$\Gamma_{C_1 C_2}(r=50)$')
ax = plt.gca()
ax.grid(False)
plt.show()

tcm = topographicalCorrelationMap(pc,'Celltype','$C_2$','Celltype','$C_1$',radiusOfInterest=50,maxCorrelationThreshold=5.0,kernelRadius=150,kernelSigma=50,visualiseStages=False)


l = int(np.ceil(np.max(np.abs([tcm.min(),tcm.max()]))))
plt.imshow(tcm,cmap='RdBu_r',vmin=-l,vmax=l,origin='lower')
plt.colorbar(label='$\Gamma_{C_2 C_1}(r=50)$')
ax = plt.gca()
ax.grid(False)
plt.show()

```


## wPCF

```{python}


#%% Calculate wPCFs - Synthetic Dataset I (Fig 4)

def weightingFunction(p,l_B):
    weights = 1-np.abs(p-l_B)/0.2
    weights = np.maximum(weights, np.zeros(np.shape(weights)))
    return weights

w = [weightingFunction(0.5, v) for v in np.linspace(0,1,101)]
plt.figure()
plt.plot(np.linspace(0,1,101),w)

r, targetP, wPCF = weightedPairCorrelationFunction(pc, 'Celltype', '$C_1$', '$m$',maxR=maxR,annulusStep=annulusStep,annulusWidth=annulusWidth,targetP=np.arange(0,1.01,0.01),weightingFunction=weightingFunction)
plotWeightedPCF(r,targetP,wPCF,vmin=0,vmax=2,ax=None,cm='plasma')

plt.figure(figsize=(18,18))
for v in np.arange(0,len(targetP),25):
    plt.plot(r,wPCF[:,v],label=f'$m = {targetP[v]}$',c=plt.cm.Oranges(v/len(targetP)),lw=5)
plt.legend()
plt.xlabel('Radius (r)')
plt.ylabel('wPCF($r$, $C_1$, $m$)')
plt.gca().axhline(1,c='k',linestyle=':',lw=3)
plt.ylim([0,10.5])

```


# Synthetic dataset 2

The second synthetic dataset comprises two distinct point patterns, each containing cells of types, C1, C2,and C3 (see Figure 3). In both patterns, three cluster centers are positioned at x, y ðÞ¼200,200 ð, 5 Þ00,800 ð, 8 Þ00,200 ð . Fo Þr the first point cloud, each cluster contains 25 cells from two different cell types, with locations chosen from a 2D normal distribution (mean μ at the cluster center, standard deviation σ ¼ 50), so that all three pairwise combinations of cell types are represented (for a total of 50 cells of each type). The same process is used to generate the second point cloud, except all three cell types are present in each cluster (i.e., a total of 75 cells of each type). By contrast, in the first pattern, no cluster contains all three cell types but each pairwise combination of cell types is present in one cluster.

```{python}

np.random.seed(1536)
clusterCentres = np.asarray([[0.2,0.2],[0.5,0.8],[0.8,0.2]])
labelsPresent = [['$C_1$','$C_2$'],['$C_1$','$C_3$'],['$C_2$','$C_3$']]

points = np.empty(shape=(0,2))
labels = []

# background noise
nBackground = 0
for l in ['$C_1$','$C_2$','$C_3$']:
    points = np.vstack([points, np.random.rand(nBackground,2)])
    labels.extend([l for v in range(nBackground)])

sigma = 0.05
nPoints = 25
for j in range(3):
    mu = clusterCentres[j]
    l = labelsPresent[j]
    points = np.vstack([points, mu + sigma*np.random.randn(2*nPoints,2)])
    labels.extend([l[0] for v in range(nPoints)])
    labels.extend([l[1] for v in range(nPoints)])

    
pc_pairwise = generatePointCloud('Pairwise Correlation Only', points*1000,domain=([[0,1000],[0,1000]]))
pc_pairwise.addLabels('Celltype', 'categorical', labels)



#%% Make synthetic data which correlates pairwise AND three-wise in the same way
clusterCentres = np.asarray([[0.2,0.2],[0.5,0.8],[0.8,0.2]])
labelsPresent = [['$C_1$','$C_2$','$C_3$'],['$C_1$','$C_2$','$C_3$'],['$C_1$','$C_2$','$C_3$']]

points = np.empty(shape=(0,2))
labels = []

# background noise
nBackground = 0
for l in ['$C_1$','$C_2$','$C_3$']:
    points = np.vstack([points, np.random.rand(nBackground,2)])
    labels.extend([l for v in range(nBackground)])

sigma = 0.05
nPoints = 25
for j in range(3):
    mu = clusterCentres[j]
    l = labelsPresent[j]
    points = np.vstack([points, mu + sigma*np.random.randn(3*nPoints,2)])
    labels.extend([l[0] for v in range(nPoints)])
    labels.extend([l[1] for v in range(nPoints)])
    labels.extend([l[2] for v in range(nPoints)])

    
pc_threewise = generatePointCloud('Three-way correlation', points*1000,domain=([[0,1000],[0,1000]]))
pc_threewise.addLabels('Celltype', 'categorical', labels)


#%% Visualise point clouds
visualisePointCloud(pc_pairwise,'Celltype',markerSize=100)
visualisePointCloud(pc_threewise,'Celltype',markerSize=100)

```


## pair wise PCF

```{python}


for pc in [pc_pairwise, pc_threewise]:
    plt.figure(figsize=(20,20))
    plt.gca().axhline(1,c='k',linestyle=':',lw=4)
    for cellpairs in [['$C_1$','$C_2$'],['$C_1$','$C_3$'],['$C_2$','$C_3$']]:
        maxR = 1000
        annulusStep = 10
        annulusWidth = 50
        r, pcf, contributions = pairCorrelationFunction(pc, 'Celltype', cellpairs, maxR=maxR,annulusStep=annulusStep,annulusWidth=annulusWidth)
        label = '$g_{C_'+cellpairs[0][3]+' C_'+cellpairs[1][3]+'}(r)$'
        plt.plot(r,pcf,lw=5,label=label)
        plt.xlabel('Radius, $r$ ($\mu$m)')
        plt.ylim([0,15])
        plt.xlim([0,1000])
    plt.title(pc.name)
    plt.legend()

```

## Neigbourhood correlation function
```{python}
bins = 30
maxR = 300

for pc in [pc_pairwise, pc_threewise]:
    circles, triplets = neighbourhoodCorrelationFunction(pc,'Celltype',['$C_1$','$C_2$','$C_3$'],maxR=maxR)
    order = np.arange(len(circles))
    np.random.shuffle(order)
        
    
    drawCircles = False
    if drawCircles:
        visualisePointCloud(pc,'Celltype',markerSize=100)
        for i in range(len(order)):
            circle = circles[order[i]]
            col = plt.cm.plasma(circle[2]/maxR)
            ec = [v for v in col]
            ec[3] = 0.25
            circle = plt.Circle((circle[0], circle[1]), circle[2], ec=col, fc=[0,0,0,0],zorder=-1)
            plt.gca().add_patch(circle)
            
        plt.gca().axis('equal')
         
    circles = np.asarray(circles)
    
    # Use bootstrapping to get predicted number of circles under CSR
    nA = 2*nPoints + nBackground
    nB = 2*nPoints + nBackground
    nC = 2*nPoints + nBackground
    
    redoBoostrap = False
    # Set this flag to true if you want to regenerate the distribution under CSR 
    # Otherwise we load in precalculated values for speed
    if redoBoostrap:
        bootstrappedRadii = []
        nBootstrap = 1000000
        for i in range(nBootstrap):
            if i % 10000 == 0:
                print(i)
            points_temp = np.random.rand(3,2)
            pc_temp = generatePointCloud('temp',points_temp,domain=[[0,1],[0,1]])
            pc_temp.addLabels('Celltype','categorical',['$C_1$','$C_2$','$C_3$'])
            circles_temp, triplets_temp = neighbourhoodCorrelationFunction(pc_temp,'Celltype',['$C_1$','$C_2$','$C_3$'],maxR=2)
            bootstrappedRadii.append(circles_temp[0][2])
        bootstrappedRadii = [v*1000 for v in bootstrappedRadii] # As this was generated in mm, not mu m
            
        vals_bootstrap, rs = np.histogram(bootstrappedRadii,bins=bins)
        vals_bootstrap = nA*nB*nC*vals_bootstrap/nBootstrap
    
    else:
        vals_observed, rs = np.histogram(circles,bins=bins)
        vals_bootstrap = np.asarray([0.375,1.375,4.875,17.625,39.25,65.875,103.75,143.75,208.875,276.5,364.625,464,578.25,713.75,856.125,997.625,1151.5,1325.88,1489.88,1684.62,1875.88,2075.88,2280.38,2495.5,2682.62,2887.62,3072.5,3305.75,3487.88,3617])
    
    plt.figure(figsize=(18,18))
    plt.plot(rs[1:],vals_bootstrap,label='Expectation (CSR)',lw=5)
    plt.plot(rs[1:],vals_observed,label='Observation',lw=5)
    plt.xlabel('$r$ (mm)')
    plt.ylabel('Number')
    plt.legend()
    plt.title(pc.name)
    
    plt.figure(figsize=(18,18))
    plt.plot(rs[1:],vals_observed/vals_bootstrap,lw=5)
    plt.gca().axhline(1,c='k',linestyle=':',lw=5)
    plt.xlabel('$r$ ($\mu$m)')
    plt.ylabel('NCF$_{C_1 C_2 C_3}(r)$')
    plt.title(pc.name)

```


# murine carcinoma dataset


```{python}

df = pd.read_csv('ROI-0_MainText.csv')
```

```{python}

sns.scatterplot(data=df,x='x',y='y',hue='Celltype',s=12)
plt.title('Murine carcinoma dataset')

```

Based on the data create point cloud object
```{python}

points = np.asarray([df['x'],df['y']]).transpose()


pc = generatePointCloud('ROI',points,domain=[[0,1000],[0,1000]])
pc.addLabels('Celltype','categorical',df.Celltype,cmap='tab10')

pc.changeIndividualLabelColor('Celltype', 'Epithelium', plt.cm.tab10(0))
pc.changeIndividualLabelColor('Celltype', 'T Helper Cell', plt.cm.tab10(1))
pc.changeIndividualLabelColor('Celltype', 'Macrophage', plt.cm.tab10(2))
pc.changeIndividualLabelColor('Celltype', 'Neutrophil', plt.cm.tab10(4))
pc.changeIndividualLabelColor('Celltype', 'Cytotoxic T Cell', plt.cm.tab10(3))
pc.changeIndividualLabelColor('Celltype', 'Regulatory T Cell', plt.cm.tab10(5))



```


## Figure 5 - All PCF between all cell types 

```{python}

#%% All cross-PCFs (Fig 5)
maxR=150
annulusStep = 10
annulusWidth = 10

avals = []
bvals = []
pcfs = []
for a in pc.labels['Celltype']['categories']:
    for b in pc.labels['Celltype']['categories']:
        print(a,b)
        r, pcf, contributions = pairCorrelationFunction(pc, 'Celltype', [a,b], maxR=maxR,annulusStep=annulusStep,annulusWidth=annulusWidth)
        avals.append(a)
        bvals.append(b)
        pcfs.append(pcf)

sns.set(font_scale=2.4)
fig, ax = plt.subplots(nrows=len(pc.labels['Celltype']['categories']), ncols=len(pc.labels['Celltype']['categories']),sharex=True,sharey=True)
it = 0
for i,a in enumerate(pc.labels['Celltype']['categories']):
    for j,b in enumerate(pc.labels['Celltype']['categories']):
        ax[i,j].plot(r,pcfs[it],lw=5)
        if i == 5:
            ax[i,j].set_xlabel(b)
        if j == 0:
            ax[i,j].set_ylabel(a)
        ax[i,j].set_ylim([0,10])
        ax[i,j].axhline(1,linestyle=':',c='k',lw=3)
        it = it + 1

```