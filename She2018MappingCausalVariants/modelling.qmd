---
title: Modelling yeast cross from two parents
authors:
  - name: Markus Owen
format: 
  html:
    embed-resources: true
    code-fold: true
    number-sections: true
    toc: true
    toc-depth: 3
    date: now
    date-modified: last-modified
    date-format: "MMMM DD, YYYY, HH:mm:ss"
  pdf: 
    number-sections: true
    colorlinks: true
execute:
  echo: true
jupyter: python3
---

# Modelling yeast crosses

```{python}
import numpy as np
import matplotlib.pyplot as plt
import scipy.io as sio
```

```{python}
rng = np.random.default_rng(1)
```

## Define functions

```{python}

# Parameters
num_variants = 1000  # Number of variants
num_generations = 6  # Number of generations in the intercross
num_cells_per_parent = 500  # Number of cells per parent
mean_coverage_threshold = 10  # Threshold for accurate variant calling
recombination_rate = 0.05  # Recombination rate (recombinations per unit genome length)

# Function to simulate random distribution of variants
# treats the genome as length one
def simulate_variants(num_variants):
    return np.sort(np.random.rand(num_variants))

# Function to initialize parents with marker values
def initialize_parents(num_cells_per_parent, num_variants):
    parent1 = np.random.choice([0, 1], size=num_variants)  # Parent 1 markers
    parent2 = np.random.choice([0, 1], size=num_variants)  # Parent 2 markers
    parent1 = np.zeros(num_variants)  # Parent 1 markers
    parent2 = np.ones(num_variants)  # Parent 2 markers
    cells_parent1 = np.tile(parent1, (num_cells_per_parent, 1))
    cells_parent2 = np.tile(parent2, (num_cells_per_parent, 1))
    phase_parent1 = np.ones_like(cells_parent1)
    phase_parent2 = 2*np.ones_like(cells_parent2)
    return cells_parent1, cells_parent2, phase_parent1, phase_parent2

# Function to simulate recombination with multiple segments
def simulate_recombination(cells_parent1, cells_parent2, phase_parent1, phase_parent2, num_generations, recombination_rate, variants):
    parents = np.vstack((cells_parent1, cells_parent2))
    phases = np.vstack((phase_parent1, phase_parent2))
    for generation in range(num_generations):
        print("Generation: ",generation)
        new_parents, new_phases = simulate_recombination_once(parents, phases, recombination_rate, variants)
        parents = new_parents
        phases = new_phases
    return parents, phases

# Function to simulate one round of recombination with multiple segments
# this chooses recombination sites from the set of marker locations, which isn't quite what would happen, but the effect would be the same - if the actual segment went beyond the marker any information between markers is lost anyway
# more importantly, variants are not uniformly spaced so the probability of recombination should account for that
# should pick recombination sites uniformly distributed in space and then find where the variant locations sit in relation to those points
def simulate_recombination_once(parents, phases, recombination_rate, variants):
    num_cells = parents.shape[0]
    num_variants = parents.shape[1]
    num_swaps = int(recombination_rate * num_variants)  # Number of swaps based on recombination rate
    new_cells = []
    new_phases = []
    indices = np.arange(num_cells)
    np.random.shuffle(indices)
    # print("Indices: ",indices)
    for i in range(0, len(indices), 2):
        # print("Cell pair: ",i," out of ",len(indices))
        parent1, parent2 = indices[i], indices[i+1]
        child1 = np.copy(parents[parent1])
        child2 = np.copy(parents[parent2])
        child1_phase = np.copy(phases[parent1])
        child2_phase = np.copy(phases[parent2])
        # print("child1_phase: ",child1_phase)
        # print("child2_phase: ",child2_phase)
        # choose num_swaps recombination sites
        recombination_sites = np.sort(np.random.rand(num_swaps))
        # recombination_indices = np.sort(np.random.choice(num_variants, size=num_swaps, replace=False))
        recombination_indices = variants.searchsorted(recombination_sites)
        start = recombination_indices[0]
        # swap a segment then jump two recombination sites forward
        for isite in range(0,num_swaps,2):
            if isite == num_swaps-1:
                end = num_variants
            else:
                end = recombination_indices[isite+1]
            # print("isite = ",isite,"; num_swaps = ",num_swaps)
            # print("recombination indices = ",recombination_indices,"; start = ",start,"; end = ",end)
            child1[start:end] = parents[parent2][start:end]
            child2[start:end] = parents[parent1][start:end]
            child1_phase[start:end] = phases[parent2][start:end]
            child2_phase[start:end] = phases[parent1][start:end]
            if isite < num_swaps-2:
                start = recombination_indices[isite+2]
            # print("child1_phase: ",child1_phase)
            # print("child2_phase: ",child2_phase)
        new_cells.append(child1)
        new_cells.append(child2)
        new_phases.append(child1_phase)
        new_phases.append(child2_phase)
    return np.array(new_cells), np.array(new_phases)


# Function to model missing genotypes as a Poisson process
def model_missing_genotypes(parents, mean_coverage_threshold):
    num_cells, num_variants = parents.shape
    coverage = np.random.poisson(mean_coverage_threshold, size=(num_cells, num_variants))
    missing_genotypes = np.where(coverage < mean_coverage_threshold, np.nan, parents)
    return missing_genotypes

```

```{python}
# https://stackoverflow.com/questions/1903462/how-can-i-zip-sort-parallel-numpy-arrays
def sort_by_abs_value(s, p):
    indexes = abs(s).argsort()
    return s[indexes], p[indexes]
```

## Run a simulation

```{python}
# Simulate variants
variants = simulate_variants(num_variants)

# Initialize parents with marker values
cells_parent1, cells_parent2, phase_parent1, phase_parent2 = initialize_parents(num_cells_per_parent, num_variants)

# print("Simulated Variants:", variants)
# print("Initial Parent 1 Cells:\n", cells_parent1)
# print("Initial Parent 2 Cells:\n", cells_parent2)

# Simulate recombination over generations
recombined_parents, recombined_phases = simulate_recombination(cells_parent1, cells_parent2, phase_parent1, phase_parent2, num_generations, recombination_rate, variants)

# Model missing genotypes for all parents
missing_genotypes = model_missing_genotypes(recombined_parents, mean_coverage_threshold)

# Output results
# print("Recombined Parents Markers:\n", recombined_parents)
# print("Missing Genotypes:\n", missing_genotypes)

```

## Run another simulation, storing intermediate populations

```{python}

recombination_rate = 0.2  # Recombination rate (recombinations per unit genome length)
num_generations = 6  # Number of generations in the intercross

parents = np.vstack((cells_parent1, cells_parent2))
phases = np.vstack((phase_parent1, phase_parent2))

parents_generations = []
phases_generations = []

parents_generations.append(parents)
phases_generations.append(phases)


for generation in range(num_generations):
    print("Generation: ",generation)
    new_parents, new_phases = simulate_recombination_once(parents, phases, recombination_rate, variants)
    parents = new_parents
    phases = new_phases
    parents_generations.append(parents)
    phases_generations.append(phases)


fig, ax = plt.subplots(nrows=num_generations+1,ncols=2,figsize=(8.5,7))
for generation in range(num_generations+1):
    ax[generation,0].imshow(parents_generations[generation],aspect='auto')
    ax[generation,1].imshow(phases_generations[generation],aspect='auto')

ax[0,0].set_title('Cells')
ax[0,1].set_title('Phases')
plt.show()


```

```{python}

fig, ax = plt.subplots(figsize=(8.5,7))
plt.imshow(recombined_parents,aspect='auto')
ax.set_title('Final population')

```


```{python}

# choose number of markers
num_causal_variants = 10
causal_indices = np.sort(rng.choice(num_variants, size=num_causal_variants, replace=False))
causal_weights = rng.normal(0,1,num_causal_variants)

causal_weights_sorted, causal_indices_sorted = sort_by_abs_value(causal_weights,causal_indices)

all_weights = np.zeros(num_variants)
all_weights[causal_indices] = causal_weights
```
```{python}

# generate phenotypes
phenotypes_no_noise = parents_generations[-1] @ all_weights
var_phenotypes = np.var(phenotypes_no_noise)
std_phenotypes = np.std(phenotypes_no_noise)
# unclear what is meant by "added random Gaussian noise equal to 20% of the total variance"
phenotypes = phenotypes_no_noise + rng.normal(0,0.2*std_phenotypes,phenotypes_no_noise.shape[0])
phenotypes = phenotypes_no_noise + rng.normal(0,np.sqrt(0.01*var_phenotypes),phenotypes_no_noise.shape[0])

```

```{python}
_, bins, _ = plt.hist(phenotypes_no_noise, bins=20,label='Phenotypes without noise')

plt.hist(phenotypes, bins=bins, alpha=0.5, label='with 20% additional variance')

plt.title('Histogram of phenotype distribution')
plt.legend()
```

Box plot for phenotype dependnce on strongest variant 
```{python}

i_strongest = causal_indices_sorted[-1]

p1 = phenotypes[parents_generations[-1][:,i_strongest]==1]
p0 = phenotypes[parents_generations[-1][:,i_strongest]==0]

plt.boxplot([p1,p0])
plt.title('Phenotype dependence on strongest marker')

```


```{python}
# doesn't quite work as expected - to do with rows v columns?
def vector_corr_np(data1, data2):
    data1 = np.atleast_2d(data1)
    data2 = np.atleast_2d(data2)
    mean1 = data1.mean(axis=1) 
    mean2 = data2.mean(axis=1)
    std1 = data1.std(axis=1)
    std2 = data2.std(axis=1)
    corr = ((data1*data2).mean(axis=1)-mean1*mean2)/(std1*std2)
    return corr
```

```{python}
# test = vector_corr_np(parents_generations[-1], phenotypes)
```

```{python}
# from scipy.stats import pearsonr

pr = np.zeros(num_variants)
lod1D = np.zeros(num_variants)
for i in range(num_variants): 
    pr[i] = np.corrcoef(parents_generations[-1][:,i],phenotypes)[0,1]
    # pr[i] = pearsonr(parents_generations[-1][:,i],phenotypes)
    lod1D[i] = -phenotypes.shape[0]*np.log(1-pr[i]**2)/(2*np.log(10))
```

```{python}
plt.plot(range(num_variants),pr,label='all markers')
plt.plot(causal_indices,pr[causal_indices],'xr',label='causal markers')
plt.title("Pearson's correlation for each marker with phenotype")
plt.legend()
```

```{python}
plt.plot(range(num_variants),lod1D,label='all markers')
plt.plot(causal_indices,lod1D[causal_indices],'xr',label='causal markers')
plt.title("LOD score for each marker with phenotype")
plt.legend()
```

# Working with the data

## Load trait data

```{python}
sio.matlab.matfile_version('FWselection_dependencies/trait.mat')
trait_contents = sio.matlab.loadmat('FWselection_dependencies/trait.mat')
```

`trait_contents` is a numpy array of size (1,64), each element is itself a 1x1152 numpy array of traits: 
```{python}
trait_contents['trait'].shape
trait_contents['trait'][0,0].shape
trait = np.squeeze(np.stack(np.squeeze(trait_contents['trait'])))
```

### Plot all the traits
```{python}
plt.plot(np.sort(trait).T,'*')
```

### Get the trait names

```{python}
sio.matlab.matfile_version('FWselection_dependencies/Previous Traits and Filename MAT/filename.mat')
filename_contents = sio.matlab.loadmat('FWselection_dependencies/Previous Traits and Filename MAT/filename.mat')
filename = np.squeeze(np.stack(np.squeeze(filename_contents['filename'])))
```

## Load genotype data

```{python}
sio.matlab.matfile_version('FWselection_dependencies/phasedGenotype.mat')
phasedGenotype_contents = sio.matlab.loadmat('FWselection_dependencies/phasedGenotype.mat')
phasedGenotype = phasedGenotype_contents['phasedGenotype']
```

Extract number of strains and variants (markers). 

```{python}
num_strains = phasedGenotype.shape[0]
num_variants = phasedGenotype.shape[1]

```

## Load and process `variantPos`

```{python}
sio.matlab.matfile_version('FWselection_dependencies/variantPos.mat')
variantPos_contents = sio.matlab.loadmat('FWselection_dependencies/variantPos.mat')
variantPos = np.squeeze(np.stack(np.squeeze(variantPos_contents['variantPos'])))
```


Split `variantPos` into chromosome and position variables so that we can scan 10kb on either side of each causal variant
```{python}
allPos = np.zeros(num_variants)
allChrom = np.zeros(num_variants)
pos_start = 0
for i in range(num_variants):
    tempVar = variantPos[i].split(':')
    allChrom[i] = int(tempVar[0].split('|')[1].split('_')[1])-1132
    allPos[i] = int(tempVar[1])
    if allChrom[i] == 92: 
        allChrom[i] = 17 
```

## Choose a trait to analyse

To find the index of a phenotype, e.g. Fluconazole, Tebuconazole: 

```{python}
def print_filename_indices(my_string):
    print(my_string + ' appears in indexes ')
    print(np.where(np.char.find(filename,my_string) > -1))
    print('of "filename", as')
    print(filename[np.where(np.char.find(filename,my_string) > -1)])
    print()

print_filename_indices('Fluc')

print_filename_indices('Tebu')

```

```{python}

##### In figure 2B 
i_trait = 32 # '30h-Ketoconazole.txt'
i_trait = 39 # '44h-Ketoconazole.txt'

# i_trait = 1 # '36h-Fluconazole.txt'
# i_trait = 3 # '43h-Fluconazole.txt'
# i_trait = 5 # '58h-Fluconazole.txt'

# i_trait = 33 # '30h-Tebuconazole.txt'
# i_trait = 41 # '44h-Tebuconazole.txt'
i_trait = 48 # '72h-Tebuconazole.txt'

##### In figure 3A
# i_trait = 30 # '30h-5FU.txt'
# i_trait = 36 # '44h-5FU.txt' < peaks look wrong, big peak in Chr3
# i_trait = 0 # '36h-CuSO4.txt'
# i_trait = 8 # '74h-CuSO4.txt' < this one looks better than 36h
```

## Exclude wells that don't meet coverage threshold

```{python}
variantCalls = np.sum(abs(phasedGenotype),axis=0)
s = np.sum(abs(phasedGenotype),axis=1)

# Cutoff for number of variant calls needed to include a segregant.
rowCutoff = 5500
columnCutoff = 0

traitRow = trait[i_trait,]
# https://stackoverflow.com/questions/7820809/understanding-weird-boolean-2d-array-indexing-behavior-in-numpy
x=phasedGenotype[(s>rowCutoff) & (traitRow != -1),:][:,variantCalls>columnCutoff]
# Remove edge count and plateNorm from variant calls
# variantCalls(1:13)=[];
y=traitRow[(s>rowCutoff) & (traitRow != -1)]

```

```{python}
# Normalize trait y to mean 0, variance 1
y = y - np.mean(y);
y = y/np.std(y);
```

```{python}
pr = np.zeros(x.shape[1])
lod1D = np.zeros(x.shape[1])
for i in range(x.shape[1]): 
    pr[i] = np.corrcoef(x[:,i],y)[0,1]
    # pr[i] = pearsonr(parents_generations[-1][:,i],phenotypes)
    lod1D[i] = -x.shape[0]*np.log(1-pr[i]**2)/(2*np.log(10))

```

```{python}
i_start = 0
for i in range(1,18):
    i_chrom = np.where(allChrom==i)
    tempPos = allPos[i_chrom] + i_start
    plt.plot(tempPos,lod1D[i_chrom],label=['C' + str(i)],linewidth=0.5)
    i_start = tempPos[-1]

plt.title("LOD score with normalised phenotype " + filename[i_trait])
plt.xlabel('Marker number')
plt.ylabel('LOD score')
# plt.legend()
```

## LOD scores for some phenotypes



## LOD scores for 5-FU


# Do it again with different genotype data

```{python}
sio.matlab.matfile_version('FWselection_dependencies/phasedGenotype_preEmptyWells.mat')
phasedGenotype_contents = sio.matlab.loadmat('FWselection_dependencies/phasedGenotype_preEmptyWells.mat')
phasedGenotype = phasedGenotype_contents['phasedGenotype']
```

```{python}
num_strains = phasedGenotype.shape[0]
num_variants = phasedGenotype.shape[1]
```
## Choose a trait to analyse

```{python}
##### In figure 2B 
i_trait = 32 # '30h-Ketoconazole.txt'
i_trait = 39 # '44h-Ketoconazole.txt'

# i_trait = 1 # '36h-Fluconazole.txt'
# i_trait = 3 # '43h-Fluconazole.txt'
# i_trait = 5 # '58h-Fluconazole.txt'

# i_trait = 33 # '30h-Tebuconazole.txt'
# i_trait = 41 # '44h-Tebuconazole.txt'
# i_trait = 48 # '72h-Tebuconazole.txt'

##### In figure 3A
# i_trait = 30 # '30h-5FU.txt'
# i_trait = 36 # '44h-5FU.txt' < peaks look wrong, big peak in Chr3
# i_trait = 0 # '36h-CuSO4.txt'
# i_trait = 8 # '74h-CuSO4.txt' < this one looks better than 36h
```

## Exclude wells that don't meet coverage threshold

```{python}
variantCalls = np.sum(abs(phasedGenotype),axis=0)
s = np.sum(abs(phasedGenotype),axis=1)

# Cutoff for number of variant calls needed to include a segregant.
rowCutoff = 5500
columnCutoff = 0

traitRow = trait[i_trait,]
# https://stackoverflow.com/questions/7820809/understanding-weird-boolean-2d-array-indexing-behavior-in-numpy
x=phasedGenotype[(s>rowCutoff) & (traitRow != -1),:][:,variantCalls>columnCutoff]
# Remove edge count and plateNorm from variant calls
# variantCalls(1:13)=[];
y=traitRow[(s>rowCutoff) & (traitRow != -1)]

```

```{python}
# Normalize trait y to mean 0, variance 1
y = y - np.mean(y);
y = y/np.std(y);
```

```{python}
pr = np.zeros(x.shape[1])
lod1D = np.zeros(x.shape[1])
for i in range(x.shape[1]): 
    pr[i] = np.corrcoef(x[:,i],y)[0,1]
    # pr[i] = pearsonr(parents_generations[-1][:,i],phenotypes)
    lod1D[i] = -x.shape[0]*np.log(1-pr[i]**2)/(2*np.log(10))

```

```{python}
i_start = 0
for i in range(1,18):
    i_chrom = np.where(allChrom==i)
    tempPos = allPos[i_chrom] + i_start
    plt.plot(tempPos,lod1D[i_chrom],label=['C' + str(i)],linewidth=0.5)
    i_start = tempPos[-1]

plt.title("LOD, pre-empty wells geno and normalised phenotype " + filename[i_trait])
plt.xlabel('Marker number')
plt.ylabel('LOD score')
# plt.legend()
```

# Azole responses

> This standard analysis established a locus of strong effect on the right arm of Chromosome 4

```{python}
i_chrom = np.where(allChrom==4)
tempPos = allPos[i_chrom]
tempLOD = lod1D[i_chrom]

plt.plot(tempPos,lod1D[i_chrom],label=['C' + str(i)],linewidth=0.5)

plt.title("LOD, Chromosome 4 for " + filename[i_trait])
plt.xlabel('Marker number')
plt.ylabel('LOD score')
# plt.legend()
```

Fig 2B inset is approx 230 kb of Chromosome 4. 
```{python}
i_chrom = np.where(allChrom==4)
tempPos = allPos[i_chrom]
tempLOD = lod1D[i_chrom]
i_max = tempLOD.argmax()
i_window = np.where(abs(tempPos-tempPos[i_max]) < 10000)

plt.plot(tempPos,tempLOD,label=['C' + str(i)],linewidth=0.5)
plt.plot(tempPos[i_window],tempLOD[i_window],label=['C' + str(i)],linewidth=0.5)

plt.title("LOD, Chromosome 4 for " + filename[i_trait])
plt.xlabel('Marker number')
plt.ylabel('LOD score')
plt.xlim((tempPos[i_max]-100000,tempPos[i_max]+100000))
# plt.legend()
```